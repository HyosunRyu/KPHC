{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuClass": "premium",
      "gpuType": "T4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HyosunRyu/KPHC/blob/main/KPHC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Korean Political Hate Speech Classifier"
      ],
      "metadata": {
        "id": "sZA27-49CejG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGAdyjAdF0kd"
      },
      "source": [
        "# Setting\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEpMfnEtfYMq"
      },
      "source": [
        "### (1) Install Package"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install beautifulsoup4==4.12.2\n",
        "!pip install bs4==0.0.1\n",
        "!pip install numpy==1.25.1\n",
        "!pip install pandas==2.0.3\n",
        "!pip install pip==23.1.2\n",
        "!pip install python-dateutil==2.8.2\n",
        "!pip install pytz==2023.3\n",
        "!pip install tqdm==4.65.0\n",
        "!pip install tzdata==2023.3\n",
        "!pip install urllib3==2.0.3\n",
        "!pip install wheel==0.38.4\n",
        "!pip install pytorch_lightning==2.3.0\n",
        "!pip install matplotlib==3.9.0\n",
        "!pip install tensorboard==2.17.0\n",
        "!pip install imblearn==0.0\n",
        "!pip install emoji==1.6.3\n",
        "!pip install soynlp\n",
        "!pip install transformers==3.0.0"
      ],
      "metadata": {
        "id": "CIA2p45QubGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%env CUBLAS_WORKSPACE_CONFIG=:4096:8"
      ],
      "metadata": {
        "id": "fjCOOF6GQuWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLh_ziVCHwkH"
      },
      "source": [
        "### (2) Import Package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb0113DUFE1k"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "\n",
        "from pprint import pprint\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from pytorch_lightning import LightningModule, Trainer, seed_everything, loggers\n",
        "from pytorch_lightning.callbacks import Callback\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AdamW\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "import re\n",
        "import emoji\n",
        "from soynlp.normalizer import repeat_normalize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dN1zqYeKH2JZ"
      },
      "source": [
        "### (3) Arguments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPr2_vTPFuP0"
      },
      "source": [
        "args = {\n",
        "    'random_seed': 42, # Random Seed\n",
        "    'pretrained_model': 'beomi/KcELECTRA-base-v2022',  # Transformers PLM name\n",
        "    'pretrained_tokenizer': 'beomi/KcELECTRA-base-v2022',  # Optional, Transformers Tokenizer Name. Overrides `pretrained_model`\n",
        "    'batch_size': 32,\n",
        "    'lr': 5e-6,  # Starting Learning Rate\n",
        "    'epochs': 50,  # Max Epochs\n",
        "    'max_length': 150,  # Max Length input size\n",
        "    'train_data_path': \"train_hate.txt\",  # Train Dataset file\n",
        "    'val_data_path': \"val_hate.txt\",  # Validation Dataset file\n",
        "    'test_mode': False,  # Test Mode enables `fast_dev_run`\n",
        "    'optimizer': 'AdamW',  # AdamW vs AdamP\n",
        "    'lr_scheduler': 'exp',  # ExponentialLR vs CosineAnnealingWarmRestarts\n",
        "    'fp16': True,  # Enable train on FP16(if GPU)\n",
        "    'tpu_cores': 0,  # Enable TPU with 1 core or 8 cores\n",
        "    'cpu_workers': os.cpu_count(),\n",
        "}\n",
        "args"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting the Callback"
      ],
      "metadata": {
        "id": "t8RXKltoavLQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (1) Checkpoint"
      ],
      "metadata": {
        "id": "vDKQd1AVXb_s"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FteKzZ67cyj"
      },
      "source": [
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filename='epoch{epoch}-val_recall{val_recall:.4f}_'+ datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
        "    monitor='val_recall',\n",
        "    save_top_k=3,\n",
        "    mode='max',\n",
        "    auto_insert_metric_name=False,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (2) EarlyStopping"
      ],
      "metadata": {
        "id": "l2Xmk7dHXfeH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Early stopping based on Recall\n",
        "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
        "early_stop_callback = EarlyStopping('val_recall', patience=3, mode='max')"
      ],
      "metadata": {
        "id": "ouQGU-XnVd0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2AcwMYa3nmd"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (1) Model class"
      ],
      "metadata": {
        "id": "P8Tom10Faj45"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImupuGXDGq7b"
      },
      "source": [
        "class Model(LightningModule):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.validation_step_outputs = []\n",
        "\n",
        "        self.clsfier = AutoModelForSequenceClassification.from_pretrained(self.hparams.pretrained_model)\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "            self.hparams.pretrained_tokenizer\n",
        "            if self.hparams.pretrained_tokenizer\n",
        "            else self.hparams.pretrained_model\n",
        "        )\n",
        "\n",
        "    def forward(self, **kwargs):\n",
        "        return self.clsfier(**kwargs)\n",
        "\n",
        "    def step(self, batch, batch_idx):\n",
        "        data, labels = batch\n",
        "        output = self(input_ids=data, labels=labels)\n",
        "\n",
        "        # Transformers 4.0.0+\n",
        "        loss = output.loss\n",
        "        logits = output.logits\n",
        "\n",
        "        preds = logits.argmax(dim=-1)\n",
        "\n",
        "        y_true = list(labels.cpu().numpy())\n",
        "        y_pred = list(preds.cpu().numpy())\n",
        "\n",
        "        return {\n",
        "            'loss': loss,\n",
        "            'y_true': y_true,\n",
        "            'y_pred': y_pred,\n",
        "        }\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        return self.step(batch, batch_idx)\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        output = self.step(batch, batch_idx)\n",
        "        self.validation_step_outputs.append(output)\n",
        "        return output\n",
        "\n",
        "    def epoch_end(self, outputs, state='train'):\n",
        "        loss = torch.tensor(0, dtype=torch.float)\n",
        "        for i in outputs:\n",
        "            loss += i['loss'].cpu().detach()\n",
        "        loss = loss / len(outputs)\n",
        "\n",
        "        y_true = []\n",
        "        y_pred = []\n",
        "        for i in outputs:\n",
        "            y_true += i['y_true']\n",
        "            y_pred += i['y_pred']\n",
        "\n",
        "        acc = accuracy_score(y_true, y_pred)\n",
        "        prec = precision_score(y_true, y_pred)\n",
        "        rec = recall_score(y_true, y_pred)\n",
        "        f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "        self.log(state+'_loss', float(loss), on_epoch=True, prog_bar=True)\n",
        "        self.log(state+'_acc', acc, on_epoch=True, prog_bar=True)\n",
        "        self.log(state+'_precision', prec, on_epoch=True, prog_bar=True)\n",
        "        self.log(state+'_recall', rec, on_epoch=True, prog_bar=True)\n",
        "        self.log(state+'_f1', f1, on_epoch=True, prog_bar=True)\n",
        "        print(f'[Epoch {self.trainer.current_epoch} {state.upper()}] Loss: {loss}, Acc: {acc}, Prec: {prec}, Rec: {rec}, F1: {f1}')\n",
        "        return {'loss': loss}\n",
        "\n",
        "    def on_training_epoch_end(self, outputs):\n",
        "        self.epoch_end(outputs, state='train')\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        self.epoch_end(self.validation_step_outputs, state='val')\n",
        "        self.validation_step_outputs.clear()\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        if self.hparams.optimizer == 'AdamW':\n",
        "            optimizer = torch.optim.AdamW(self.parameters(), lr=self.hparams.lr)\n",
        "        elif self.hparams.optimizer == 'AdamP':\n",
        "            from adamp import AdamP\n",
        "            optimizer = AdamP(self.parameters(), lr=self.hparams.lr)\n",
        "        else:\n",
        "            raise NotImplementedError('Only AdamW and AdamP are Supported!')\n",
        "        if self.hparams.lr_scheduler == 'cos':\n",
        "            scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=1, T_mult=2)\n",
        "        elif self.hparams.lr_scheduler == 'exp':\n",
        "            scheduler = ExponentialLR(optimizer, gamma=0.5)\n",
        "        else:\n",
        "            raise NotImplementedError('Only cos and exp lr scheduler is Supported!')\n",
        "        return {\n",
        "            'optimizer': optimizer,\n",
        "            'scheduler': scheduler,\n",
        "        }\n",
        "\n",
        "    def read_data(self, path):\n",
        "        if path.endswith('xlsx'):\n",
        "            return pd.read_excel(path)\n",
        "        elif path.endswith('csv'):\n",
        "            return pd.read_csv(path)\n",
        "        elif path.endswith('tsv') or path.endswith('txt'):\n",
        "            return pd.read_csv(path, sep='\\t')\n",
        "        else:\n",
        "            raise NotImplementedError('Only Excel(xlsx)/Csv/Tsv(txt) are Supported')\n",
        "\n",
        "    def clean(self, x):\n",
        "        emojis = ''.join(emoji.UNICODE_EMOJI.keys())\n",
        "        pattern = re.compile(f'[^ .,?!/@$%~％·∼()\\x00-\\x7Fㄱ-힣{emojis}]+')\n",
        "        url_pattern = re.compile(\n",
        "            r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)')\n",
        "        x = pattern.sub(' ', x)\n",
        "        x = url_pattern.sub('', x)\n",
        "        x = x.strip()\n",
        "        x = repeat_normalize(x, num_repeats=2)\n",
        "        return x\n",
        "\n",
        "    def encode(self, x, **kwargs):\n",
        "        return self.tokenizer.encode(\n",
        "            self.clean(str(x)),\n",
        "            padding='max_length',\n",
        "            max_length=self.hparams.max_length,\n",
        "            truncation=True,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "    def preprocess_dataframe(self, df):\n",
        "        df['document'] = df['document'].map(self.encode)\n",
        "        return df\n",
        "\n",
        "    def dataloader(self, path, shuffle=False):\n",
        "        df = self.read_data(path)\n",
        "        df = self.preprocess_dataframe(df)\n",
        "\n",
        "        dataset = TensorDataset(\n",
        "            torch.tensor(df['document'].to_list(), dtype=torch.long),\n",
        "            torch.tensor(df['label'].to_list(), dtype=torch.long),\n",
        "        )\n",
        "        return DataLoader(\n",
        "            dataset,\n",
        "            batch_size=self.hparams.batch_size * 1 if not self.hparams.tpu_cores else self.hparams.tpu_cores,\n",
        "            shuffle=shuffle,\n",
        "            num_workers=self.hparams.cpu_workers,\n",
        "        )\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return self.dataloader(self.hparams.train_data_path, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return self.dataloader(self.hparams.val_data_path, shuffle=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (2) Fine-tuning"
      ],
      "metadata": {
        "id": "uFkZZLe20y4i"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qu1QkSZsHo8x"
      },
      "source": [
        "print(\"Using PyTorch Ver\", torch.__version__)\n",
        "print(\"Fix Seed:\", args['random_seed'])\n",
        "seed_everything(args['random_seed'])\n",
        "model = Model(**args)\n",
        "\n",
        "print(\":: Start Training ::\")\n",
        "\n",
        "trainer = Trainer(\n",
        "    callbacks=[checkpoint_callback,\n",
        "               early_stop_callback],\n",
        "    max_epochs=args['epochs'],\n",
        "    fast_dev_run=args['test_mode'],\n",
        "    num_sanity_val_steps=None if args['test_mode'] else 0,\n",
        "    # For GPU Setup\n",
        "    deterministic=torch.cuda.is_available(),\n",
        "    accelerator='gpu', devices=[0] if torch.cuda.is_available() else None,  # 0번 idx GPU  사용\n",
        "    precision=16 if args['fp16'] and torch.cuda.is_available() else 32,\n",
        "    # For TPU Setup\n",
        "    # tpu_cores=args['tpu_cores'] if args['tpu_cores'] else None,\n",
        ")\n",
        "history = trainer.fit(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cyczos82ept3"
      },
      "source": [
        "# Model Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mdp3SK2etM-"
      },
      "source": [
        "from glob import glob\n",
        "best_ckpt = sorted(glob(checkpoint_callback.best_model_path))[-1]\n",
        "best_ckpt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VW-5fGmsY8QZ"
      },
      "source": [
        "model = Model.load_from_checkpoint(best_ckpt)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hate_index(x):\n",
        "  try:\n",
        "    # Check the device the model is using\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    # Tokenize and convert to tensor\n",
        "    inputs = model.tokenizer(x, return_tensors='pt')\n",
        "\n",
        "    # Move input data to the same device as the model\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # Predict using the model\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits\n",
        "\n",
        "    # Calculate the result\n",
        "    probabilities = torch.softmax(logits, dim=-1)\n",
        "    hate_prob = probabilities[0][1].item()\n",
        "\n",
        "    return hate_prob\n",
        "  except:\n",
        "        print('Excluded from analysis')\n",
        "        pass\n",
        "\n",
        "df = pd.read_csv('test_hate.txt', delimiter='\\t')\n",
        "df['hatescore'] = df['document'].map(lambda x: hate_index(x))\n",
        "\n",
        "# To binary data\n",
        "df['hatespeech'] = df['hatescore'].map(lambda x: 1 if (x >= 0.5) else 0)\n"
      ],
      "metadata": {
        "id": "dMdwTFdiJxrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the prediction results and actual labels\n",
        "y_true = df['label']  # Actual label\n",
        "y_pred = df['hatespeech']  # Prediction result\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(y_true, y_pred)\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_true, y_pred)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1}')"
      ],
      "metadata": {
        "id": "uBBYpx04ZFeT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
